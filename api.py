# ================================================================
# ğŸš€ Unified FastAPI Medical Assistant + AI Skin Disease Detector
# ================================================================

import os
import torch
import pandas as pd
from PIL import Image
from doctors_api import get_doctors
from io import BytesIO
from fastapi import FastAPI, File, UploadFile
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    AutoModelForImageClassification,
    AutoImageProcessor,
)
from groq import Groq
from langdetect import detect
from deep_translator import GoogleTranslator
import joblib
from dotenv import load_dotenv

# ================================================================
# âš™ï¸ LOAD .env VARIABLES
# ================================================================
load_dotenv()  # Load environment variables from .env
GROQ_KEY = os.environ.get("GROQ_API_KEY")
if not GROQ_KEY:
    raise ValueError("GROQ_API_KEY not found. Please set it in your .env file.")

client = Groq(api_key=GROQ_KEY)

# ================================================================
# âš™ï¸ CONFIGURATION
# ================================================================
app = FastAPI(
    title="AI Medical Assistant + Skin Disease Detector",
    version="2.0",
    description="Unified API for symptom-based chatbot and image-based skin disease detection.",
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], allow_credentials=True,
    allow_methods=["*"], allow_headers=["*"],
)

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# ================================================================
# ğŸ’¬ CHATBOT MODEL SETUP
# ================================================================
model_path = "my_chatbot_model"
tokenizer = AutoTokenizer.from_pretrained(model_path)
chat_model = AutoModelForSequenceClassification.from_pretrained(model_path).to(DEVICE)

le = joblib.load("label_encoder.pkl")
desc_df = pd.read_csv("symptom_Description.csv")
prec_df = pd.read_csv("symptom_precaution.csv")

disease_desc = dict(zip(desc_df["Disease"], desc_df["Description"]))
disease_prec = prec_df.set_index("Disease").T.to_dict("list")

# ================================================================
# ğŸ©º IMAGE MODEL SETUP
# ================================================================
IMAGE_MODEL_NAME = "Jayanth2002/dinov2-base-finetuned-SkinDisease"
image_model = AutoModelForImageClassification.from_pretrained(IMAGE_MODEL_NAME).to(DEVICE)
image_processor = AutoImageProcessor.from_pretrained(IMAGE_MODEL_NAME)

# ================================================================
# ğŸŒ TRANSLATIONS, GREETINGS
# ================================================================
disease_translations = {
    "Common Cold": {"ar": "Ù†Ø²Ù„Ø© Ø¨Ø±Ø¯", "fr": "Rhume commun"},
    "Diabetes": {"ar": "Ø¯Ø§Ø¡ Ø§Ù„Ø³ÙƒØ±ÙŠ", "fr": "DiabÃ¨te"},
    "Migraine": {"ar": "ØµØ¯Ø§Ø¹ Ù†ØµÙÙŠ", "fr": "Migraine"},
    "Malaria": {"ar": "Ø§Ù„Ù…Ù„Ø§Ø±ÙŠØ§", "fr": "Paludisme"},
    "Tuberculosis": {"ar": "Ø§Ù„Ø³Ù„", "fr": "Tuberculose"},
}

greetings = {
    "ar": ["Ø§Ù‡Ù„Ø§", "Ù…Ø±Ø­Ø¨Ø§", "Ù‡Ù„Ø§", "Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ…"],
    "en": ["hello", "hi", "hey"],
    "fr": ["bonjour", "salut"]
}

greeting_responses = {
    "ar": "Ø£Ù‡Ù„Ø§ Ø¨ÙŠÙƒ ğŸ‘‹ØŒ Ù‚ÙˆÙ„Ù„ÙŠ Ø£Ø¹Ø±Ø§Ø¶ÙƒØŸ",
    "en": "Hello ğŸ‘‹, tell me your symptoms?",
    "fr": "Bonjour ğŸ‘‹, dites-moi vos symptÃ´mes?"
}

# ================================================================
# ğŸ”® CHATBOT FUNCTIONS
# ================================================================
current_lang = "en"
chat_history = []

def predict_top(symptoms_text, lang=None, top_n=10):
    text_en = GoogleTranslator(source="auto", target="en").translate(symptoms_text)
    inputs = tokenizer(text_en, return_tensors="pt", truncation=True, padding=True).to(DEVICE)
    with torch.no_grad():
        outputs = chat_model(**inputs)
        probs = torch.softmax(outputs.logits, dim=1).cpu().numpy()[0]

    top_idx = probs.argsort()[-top_n:][::-1]
    diseases = le.inverse_transform(top_idx)
    confidences = probs[top_idx]

    if lang is None:
        lang = detect(symptoms_text)

    translated = [disease_translations.get(d, {}).get(lang, d) for d in diseases]
    return list(zip(diseases, translated, confidences))

def predict_disease(symptoms_text, lang=None):
    top = predict_top(symptoms_text, lang, top_n=10)
    return top[0]

def chatbot(user_input):
    global current_lang

    # Language switching
    if any(word in user_input.lower() for word in ["ÙƒÙ„Ù…Ù†ÙŠ Ø¹Ø±Ø¨ÙŠ", "speak arabic"]):
        current_lang = "ar"; return "ØªÙ…Ø§Ù… âœ… Ù‡ÙƒÙ„Ù…Ùƒ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠ!"
    if any(word in user_input.lower() for word in ["speak english", "ÙƒÙ„Ù…Ù†ÙŠ Ø§Ù†Ø¬Ù„ÙŠØ²ÙŠ"]):
        current_lang = "en"; return "Okay âœ… I'll speak English now!"
    if any(word in user_input.lower() for word in ["speak french", "ÙƒÙ„Ù…Ù†ÙŠ ÙØ±Ù†Ø³ÙŠ"]):
        current_lang = "fr"; return "ØªÙ…Ø§Ù… âœ… Ù‡ÙƒÙ„Ù…Ùƒ Ø¨Ø§Ù„ÙØ±Ù†Ø³Ø§ÙˆÙŠ Ù…Ù† Ø¯Ù„ÙˆÙ‚ØªÙŠ!"

    # Greetings
    for lang, words in greetings.items():
        if any(word in user_input.lower() for word in words):
            return greeting_responses.get(current_lang, greeting_responses["en"])

    # Predict Disease
    disease_en, disease_out, prob = predict_disease(user_input, current_lang)
    description = disease_desc.get(disease_en, "No description available.")
    precautions = [p for p in disease_prec.get(disease_en, []) if isinstance(p, str) and p.strip() != ""]

    response = {
        "response": f"ğŸ“‹ Expected Disease: {disease_out} (Confidence: {prob:.2f})\n\n"
                    f"ğŸ“ Description: {description}\n\n"
                    + ("âœ… Precautions:\n" + "\n".join([f"{i+1}. {p}" for i, p in enumerate(precautions)]) if precautions else ""),
        "disease": disease_out,
        "description": description,
        "precautions": precautions,
        "confidence": float(prob)
    }
    return response

from doctors_api import get_doctors

@app.get("/find_doctors")
async def find_doctors(disease: str = None, symptom: str = None):
    """
    ğŸ” Find doctors by disease or symptom.
    Example: /find_doctors?disease=Diabetes
    """
    result = get_doctors(disease=disease, symptom=symptom)
    return result


# ================================================================
# ğŸ§  IMAGE DETECTION FUNCTIONS
# ================================================================
def predict_skin_disease(image: Image.Image):
    image = image.convert("RGB")
    inputs = image_processor(images=image, return_tensors="pt").to(DEVICE)
    with torch.no_grad():
        outputs = image_model(**inputs)
    logits = outputs.logits
    predicted_class_idx = logits.argmax(-1).item()
    predicted_label = image_model.config.id2label[predicted_class_idx]
    return predicted_label

def get_disease_info_groq(disease_name: str):
    prompt = f"Provide a detailed explanation about the skin disease '{disease_name}', including description, causes, precautions, risks, and treatment options."
    chat_completion = client.chat.completions.create(
        messages=[{"role": "user", "content": prompt}],
        model="llama-3.3-70b-versatile",
    )
    return chat_completion.choices[0].message.content

# ================================================================
# ğŸ“¦ FASTAPI SCHEMAS
# ================================================================
class ChatRequest(BaseModel):
    message: str

# ================================================================
# ğŸŒ ENDPOINTS
# ================================================================
@app.get("/")
async def root():
    return {"message": "AI Medical Assistant + Skin Disease Detector running ğŸš€"}

# ğŸ—£ï¸ Chatbot endpoint
@app.post("/chat")
async def chat_endpoint(req: ChatRequest):
    chat_resp = chatbot(req.message)
    chat_history.append({"user": req.message, "bot": chat_resp["response"]})
    top10 = predict_top(req.message, current_lang, top_n=10)
    top10_list = [{"disease_en": d[0], "disease_translated": d[1], "confidence": float(d[2])} for d in top10]
    return {"chat": chat_resp, "history": chat_history, "top10": top10_list}

# ğŸ–¼ï¸ Skin Disease Detection endpoint
@app.post("/image")
async def detect_disease(file: UploadFile = File(...)):
    contents = await file.read()
    image = Image.open(BytesIO(contents))
    disease_name = predict_skin_disease(image)
    disease_info = get_disease_info_groq(disease_name)
    return {
        "detected_disease": disease_name,
        "details": disease_info
    }

# ================================================================
# â–¶ï¸ MAIN
# ================================================================
if __name__ == "__main__":
    import uvicorn
    uvicorn.run("api:app", host="127.0.0.1", port=8000, reload=True)
